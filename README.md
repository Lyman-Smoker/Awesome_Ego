# Awesome Egocentric Action Understanding
Egocentric Action Understanding (EAU) aims at understanding human actions based on videos shot by first-person cameras.

In this reprository, interetsting papers in EAU are collected to show the development of the EAU community.

### Survey
- A Survey on 3D Egocentric Human Pose Estimation **(2024 ArXiv)** [[Paper]](https://arxiv.org/abs/2403.17893)
- An Outlook into the Future of Egocentric Vision **(2023 ArXiv)** [[Paper]](https://arxiv.org/pdf/2308.07123.pdf) [[Citations]](https://scholar.google.com/scholar?cites=15098752443409016265&as_sdt=2005&sciodt=0,5&hl=en)
 

### 2024
- Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives **(CVPR 2024)** [[Project]](https://ego-exo4d-data.org/#people) [[Paper]](https://ego-exo4d-data.org/paper/ego-exo4d.pdf) [[Citations]](https://scholar.google.com/scholar?cites=6807725739327920288&as_sdt=2005&sciodt=0,5&hl=en)
- EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World **(CVPR 2024)** [[Paper]](https://arxiv.org/pdf/2403.16182.pdf) [[Code]](https://github.com/OpenGVLab/EgoExoLearn/)
- PREGO: online mistake detection in PRocedural EGOcentric videos **(CVPR 2024)** [[Paper]](https://arxiv.org/abs/2404.01933) [[Code]](https://github.com/aleflabo/PREGO)
- 3D Human Pose Perception from Egocentric Stereo Videos **(CVPR 2024)**
- X-MIC: Cross-Modal Instance Conditioning for Egocentric Action Generalization **(CVPR 2024)** [[Code]](https://github.com/Annusha/xmic)
- A Backpack Full of Skills: Egocentric Video Understanding with Diverse Task Perspectives **(CVPR 2024)** [[Paper]](https://arxiv.org/pdf/2403.03037.pdf) [[Project]](https://sapeirone.github.io/EgoPack/)

### 2023
- Ego-Body Pose Estimation via Ego-Head Pose Estimation **(CVPR 2023)** [[Project]](https://lijiaman.github.io/projects/egoego/) [[Paper]](http://openaccess.thecvf.com/content/CVPR2023/html/Li_Ego-Body_Pose_Estimation_via_Ego-Head_Pose_Estimation_CVPR_2023_paper.html) [[Code]](https://github.com/lijiaman/egoego_release) [[Citations]](https://scholar.google.com/scholar?cites=4815197793392724124&as_sdt=2005&sciodt=0,5&hl=en)
- IndustReal: A Dataset for Procedure Step Recognition Handling Execution Errors in Egocentric Videos in an Industrial-Like Setting **(WACV 2023)** [[Paper]](https://arxiv.org/pdf/2310.17323.pdf) [[Code]](https://github.com/TimSchoonbeek/IndustReal)
- EgoVLPv2: Egocentric Video-Language Pre-training with Fusion in the Backbone **(ICCV 2023)** [[Paper]](https://openaccess.thecvf.com/content/ICCV2023/html/Pramanick_EgoVLPv2_Egocentric_Video-Language_Pre-training_with_Fusion_in_the_Backbone_ICCV_2023_paper.html) [[Project]](https://shramanpramanick.github.io/EgoVLPv2/) [[Code]](https://github.com/facebookresearch/EgoVLPv2) [[Citations]](https://scholar.google.com/scholar?cites=2418402012858604493&as_sdt=2005&sciodt=0,5&hl=en)
- Weakly-Supervised Action Segmentation and Unseen Error Detection in Anomalous Instructional Videos **(ICCV 2023)** [[Project]](https://usa.honda-ri.com/ata) [[Paper]](https://openaccess.thecvf.com/content/ICCV2023/html/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.html) 
- HoloAssist: an Egocentric Human Interaction Dataset for Interactive AI Assistants in the Real World **(ICCV 2023)** [[Project]](https://holoassist.github.io) [[Paper]](http://openaccess.thecvf.com/content/ICCV2023/html/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.html) [[Citations]](https://scholar.google.com/scholar?cites=1935067381543829055&as_sdt=2005&sciodt=0,5&hl=en) [[Citations]](https://scholar.google.com/scholar?cites=1935067381543829055&as_sdt=2005&sciodt=0,5&hl=en)
- CaptainCook4D: A dataset for understanding errors in procedural activities **(ICMLW 2023)** [[Project]](https://captaincook4d.github.io/captain-cook/) [[Paper]](https://arxiv.org/abs/2312.14556) [[Code]](https://github.com/CaptainCook4D)
- Every Mistake Counts in Assembly **(ArXiv 2023)** [[Paper]](https://arxiv.org/abs/2307.16453) [[Code]](https://github.com/assembly-101/assembly101-mistake-detection)

### 2022
- Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities **(CVPR 2022)** [[Project]](https://assembly-101.github.io) [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Sener_Assembly101_A_Large-Scale_Multi-View_Video_Dataset_for_Understanding_Procedural_Activities_CVPR_2022_paper.pdf) [[Code]](https://github.com/assembly-101?tab=repositories) [[Citations]](https://scholar.google.com/scholar?cites=16985062727042180828&as_sdt=2005&sciodt=0,5&hl=en)
